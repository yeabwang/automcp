# =============================================================================
# AutoMCP Default Configuration - Core Framework
# =============================================================================
# Base configuration shared across all environments
# Environment-specific configs inherit from this and override as needed

$schema: "../schemas/automcp-config-v1.schema.json"
version: "1.0.0"
environment: "default"

# =============================================================================
# Profile Configuration
# =============================================================================
profile: "development"  # Default profile

profiles:
  development:
    enrichment.batch_size: 4
    logging.level: debug
    validation.strict: false
    output.strict_validation: false
    mcp.generate_tools: true
    mcp.generate_examples: true
    exporter.api_auth: false
    security.encrypt_outputs: false
  production:
    enrichment.batch_size: 16
    logging.level: info
    validation.strict: true
    output.strict_validation: true
    mcp.generate_tools: true
    mcp.generate_examples: true
    exporter.api_auth: true
    security.encrypt_outputs: true
  enterprise:
    enrichment.batch_size: 32
    logging.level: warning
    validation.strict: true
    output.strict_validation: true
    mcp.generate_tools: true
    mcp.generate_examples: true
    exporter.api_auth: true
    security.encrypt_outputs: true
    use_memory: true

# =============================================================================
# Core Parser Configuration
# =============================================================================
parsers_order:
  - openapi
  - rest
  - postman
  - scraping

flatten_depth:
  openapi: 5
  rest: 3
  postman: 3
  scraping: 5
  default: 5

parser_workers: 4
spec_file_priorities:
  - openapi.yaml
  - openapi.json
  - swagger.yaml
  - swagger.json
  - postman.json

# New nested structure (preferred)
parsers:
  order:
    - openapi
    - rest
    - postman
    - scraping
  flatten_depth:
    openapi: 5
    rest: 3
    postman: 3
    scraping: 5
    default: 5
  workers: 4
  timeout: 30

# =============================================================================
# General Flags Configuration
# =============================================================================
log_progress: true
profile_enrichment: false

# =============================================================================
# Semantic Transformation Configuration
# =============================================================================
semantic_transformation:
  enabled: true
  mode: "llm_driven"
  confidence_threshold: 0.7
  required_intent_details: ["summary", "complexity", "user_context"]

  # Domain patterns - core set
  domain_patterns:
    e_commerce: ["product", "order", "cart", "payment", "checkout", "inventory"]
    user_management: ["user", "profile", "account", "auth", "login", "session"]
    content_management: ["content", "article", "post", "media", "publish"]
    communication: ["message", "email", "notification", "chat", "sms"]
    analytics: ["analytics", "metric", "report", "dashboard", "track"]
    finance: ["payment", "invoice", "transaction", "balance", "account"]
    healthcare: ["patient", "appointment", "prescription", "diagnosis"]
    logistics: ["shipment", "tracking", "delivery", "route", "warehouse"]
    education: ["course", "lesson", "enrollment", "grade", "student"]
    aws_cloudsearch: ["search", "suggest", "index", "domain", "document", "batch", "upload"]

  # Core complexity levels
  complexity_levels:
    - name: "simple"
      description: "Basic CRUD operations with minimal parameters"
      max_parameters: 3
      max_nesting_depth: 1
    - name: "moderate"
      description: "Standard operations with some business logic"
      max_parameters: 7
      max_nesting_depth: 3
    - name: "complex"
      description: "Advanced operations with significant logic"
      max_parameters: 15
      max_nesting_depth: 5
    - name: "multi_step"
      description: "Operations requiring multiple API calls or workflows"
      max_parameters: 999
      max_nesting_depth: 999

  # Core user contexts
  user_contexts:
    - name: "anonymous_visitor"
      description: "Unauthenticated users accessing public endpoints"
      auth_required: false
      typical_operations: ["read", "search", "list"]
    - name: "browsing_user"
      description: "Users exploring public data without commitment"
      auth_required: false
      typical_operations: ["read", "search", "filter"]
    - name: "authenticated_user"
      description: "Logged-in users with standard privileges"
      auth_required: true
      typical_operations: ["read", "create", "update"]
    - name: "premium_user"
      description: "Users with enhanced privileges"
      auth_required: true
      typical_operations: ["read", "create", "update", "bulk"]
    - name: "admin_user"
      description: "Administrative users with elevated privileges"
      auth_required: true
      typical_operations: ["all"]
    - name: "system_service"
      description: "API-to-API automated interactions"
      auth_required: true
      typical_operations: ["all"]

  # Permission level mappings
  permission_levels:
    white:
      description: "Safe read-only operations"
      risk_level: "low"
      typical_methods: ["GET", "HEAD", "OPTIONS"]
      requires_auth: false
    grey:
      description: "User-specific write operations"
      risk_level: "medium"
      typical_methods: ["POST", "PUT", "PATCH"]
      requires_auth: true
    black:
      description: "Administrative or destructive operations"
      risk_level: "high"
      typical_methods: ["DELETE", "POST", "PUT"]
      requires_auth: true
      additional_checks: ["audit_logging", "rate_limiting"]

  # Authentication type mappings
  auth_type_mappings:
    apiKey: "api_key"
    http: "http_auth"
    oauth2: "oauth"
    openIdConnect: "openid_connect"
    basic: "basic_auth"
    bearer: "bearer_token"
    digest: "digest_auth"
    custom: "custom_auth"

  # Sensitive data patterns for PII detection
  sensitive_data_patterns:
    high_sensitivity:
      - "password"
      - "secret"
      - "key"
      - "token"
      - "credit_card"
      - "ssn"
      - "tax_id"
      - "medical_record"
      - "api_key"
      - "access_token"
    medium_sensitivity:
      - "email"
      - "phone_number"
      - "address"
      - "profile"
      - "personal_id"
      - "ip_address"
    low_sensitivity:
      - "name"
      - "username"
      - "id"
      - "public_data"

  # LLM prompts for domain-aligned outputs
  max_prompt_length: 8000

  llm_prompts:
    semantic_naming: |
      You are an expert API semantic analyzer. Transform this technical OpenAPI endpoint into a semantic function name that aligns with the input API's domain.

      Input:
      - HTTP Method: {method}
      - Path: {path}
      - Summary: {summary}
      - Parameters: {parameters}
      - Domain Context: {domain_context}

      Guidelines:
      - Use action-oriented naming (e.g., search_products for e-commerce, retrieve_patient_records for healthcare).
      - Follow REST conventions (GET=search/list, POST=create, PUT=update, DELETE=remove).
      - Use domain-specific terms from {domain_context} to ensure relevance.
      - Use snake_case format.
      - Be specific but concise.

      Return only the semantic name as a single string, no explanation.
    
    complexity_analysis: |
      Analyze the complexity of this API endpoint based on its structure.

      Input:
      - Parameters: {parameters}
      - Request Body: {request_body}
      - Response Schema: {response_schema}
      - Semantic Name: {semantic_name}

      Complexity Factors:
      - Parameter count and nesting depth
      - Request body complexity
      - Response schema complexity
      - Business logic implied by semantic name
      - Inter-dependency requirements

      Complexity Levels:
      - simple: Basic CRUD, few parameters, straightforward response
      - moderate: Some business logic, moderate parameters, structured response
      - complex: Multiple parameters, nested objects, complex business rules
      - multi_step: Requires multiple API calls or complex orchestration

      Return only one word: simple, moderate, complex, or multi_step
    
    user_context_inference: |
      Infer the most likely user context for this API endpoint based on its semantic purpose.

      Input:
      - Semantic Name: {semantic_name}
      - HTTP Method: {method}
      - Path: {path}
      - Authentication Required: {auth_required}
      - Domain Context: {domain_context}

      User Context Options:
      - anonymous_visitor: Public endpoints, no auth
      - browsing_user: Public data browsing or searching
      - authenticated_user: User-specific operations
      - premium_user: Advanced or premium features
      - admin_user: Administrative functions
      - system_service: API-to-API or automated processes

      Consider:
      - Semantic action and domain context
      - Authentication requirements
      - Data sensitivity
      - Typical usage patterns

      Return only one user context.
    
    permission_inference: |
      Determine the appropriate permission level for this API endpoint.

      Input:
      - Semantic Name: {semantic_name}
      - HTTP Method: {method}
      - User Context: {user_context}
      - Data Sensitivity: {data_sensitivity}
      - Domain Context: {domain_context}

      Permission Levels:
      - white: Safe read operations, public data
      - grey: Authenticated user operations, moderate risk
      - black: Admin or high-risk operations, sensitive data

      Classification Rules:
      - GET with public data → white
      - User data operations → grey
      - Admin, destructive, or financial operations → black

      Return only: white, grey, or black
    
    auth_requirement_inference: |
      Infer authentication requirements for this endpoint.

      Input:
      - Semantic Name: {semantic_name}
      - HTTP Method: {method}
      - Path: {path}
      - User Context: {user_context}
      - Permission Level: {permission_level}
      - Domain Context: {domain_context}

      Consider:
      - Public vs private data access
      - User-specific operations
      - Security sensitivity
      - Industry standards

      Return JSON:
      {
        "type": "api_key|oauth|basic_auth|none",
        "required": true|false,
        "scope": "optional_scope_for_oauth"
      }
    
    tool_description_generation: |
      Generate a comprehensive description for this MCP tool, aligned with the input API's domain.

      Input:
      - Semantic Name: {semantic_name}
      - Summary: {summary}
      - Parameters: {parameters}
      - User Context: {user_context}
      - Complexity: {complexity}
      - Domain Context: {domain_context}

      Requirements:
      - Describe the tool's purpose and key capabilities.
      - Use domain-specific terms from {domain_context}.
      - Be concise (1-2 sentences).
      - Use professional, technical language.

      Return only the description text.
    
    prompt_template_generation: |
      Create a natural language prompt template for this API tool, aligned with the input API's domain.

      Input:
      - Semantic Name: {semantic_name}
      - Description: {description}
      - Parameters: {parameters}
      - Examples: {examples}
      - Domain Context: {domain_context}

      Requirements:
      - Use {param_name} placeholders.
      - Be conversational and suitable for AI agents.
      - Include key parameters.
      - Use domain-specific terms from {domain_context}.

      Return only the template string.
    
    usage_examples_generation: |
      Generate realistic usage examples for this API tool, aligned with the input API's domain.

      Input:
      - Semantic Name: {semantic_name}
      - Description: {description}
      - Input Schema: {input_schema}
      - Domain Context: {domain_context}

      Requirements:
      - Generate 2-3 diverse, realistic examples.
      - Use function call format: function_name(param=value, ...).
      - Include realistic, domain-appropriate parameter values.
      - Show varied use cases.

      Return as JSON array of strings.

  quality_thresholds:
    min_confidence: 0.6
    semantic_name_min_length: 3
    semantic_name_max_length: 50
    description_min_length: 20
    description_max_length: 200
    summary_min_length: 10
    summary_max_length: 200
    example_min_length: 5
    example_max_count: 5
    capability_name_min_length: 3
    capability_name_max_length: 50

  fallback_strategies:
    semantic_naming: "pattern_based"
    complexity: "parameter_count"
    user_context: "authenticated_user"
    permission: "grey"

  # Caching configuration
  caching:
    enabled: true
    ttl_hours: 24
    cache_by_signature: true
    max_cache_size: 10000

# =============================================================================
# Enrichment Configuration
# =============================================================================
enrichment:
  batch_size: 8
  max_batch_size: 20
  cpu_threshold: 70
  mem_threshold: 80
  use_memory: false
  confidence_thresholds:
    auto_accept: 0.85
    clarify: 0.30
  retry_attempts: 3
  timeout_seconds: 30
  retry_wait_seconds: 1
  adapt_throttle_seconds: 10
  resource_sample_interval: 0.1
  batch_growth_factor: 2
  fallback_confidence: 0.5
  fallbacks:
    action: "perform_operation"
    object: "resource"
    summary: "User wants to perform an operation"
    classification: "grey"
  
  # Multi-stage processing pipeline
  processing_stages:
    - technical_extraction
    - semantic_transformation
    - context_inference
    - security_analysis
    - mcp_generation
    - validation
  
  # Stage-specific settings
  stage_settings:
    semantic_transformation:
      batch_size: 5
      timeout_seconds: 45
      retry_attempts: 3
    context_inference:
      batch_size: 8
      timeout_seconds: 30
      parallel_processing: true
    mcp_generation:
      batch_size: 3
      timeout_seconds: 60
      include_validation: true

# =============================================================================
# Output Configuration
# =============================================================================
output:
  output_dir: outputs/
  save_format: json
  versioning: false
  strict_validation: true
  editable: true
  quality_assessment:
    enabled: true
    generate_report: true
    min_acceptable_score: 70
    grading_thresholds:
      A: 90
      B: 80
      C: 70
      D: 60
      F: 0
    use_llm_assessment: true
    max_issues_threshold: 5
    sampling_rate: 1.0

# =============================================================================
# Logging Configuration
# =============================================================================
logging:
  level: info
  format: "console"
  redact_keys:
    - auth_token
    - api_key
    - credentials
    - password
    - secret
    - token
    - phone_number
    - email
    - ssn
    - credit_card

# =============================================================================
# Validation Configuration
# =============================================================================
validation:
  strict: true
  semantic_name_pattern: '^[a-z][a-z0-9_]*[a-z0-9]$'
  semantic_name_reserved_words: ["class", "def", "return", "import", "from"]
  valid_http_methods: ["GET", "POST", "PUT", "PATCH", "DELETE", "HEAD", "OPTIONS"]
  max_schema_depth: 10
  max_array_items: 1000
  valid_content_types:
    - "application/json"
    - "application/xml"
    - "application/x-www-form-urlencoded"
    - "multipart/form-data"
    - "text/plain"
    - "text/html"

# =============================================================================
# LLM Client Configuration
# =============================================================================
llm_client:
  provider: "groq"
  endpoint: ""
  api_key: ""
  model: "llama-3.1-8b-instant"
  timeout: 60

  # =========================================================================
  # SSL/TLS Security Configuration (Production-Ready)
  # =========================================================================
  ssl:
    verify_ssl: true                    # Enable SSL certificate verification
    verify_hostname: true               # Verify hostname against certificate
    min_tls_version: "TLSv1_2"         # Minimum TLS version (TLSv1_2, TLSv1_3)
    max_tls_version: ""                 # Maximum TLS version (optional)
    ciphers: "ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!MD5:!DSS"
    post_handshake_auth: false          # Enable post-handshake authentication
    ca_bundle_path: ""                  # Custom CA bundle path (optional)
    client_cert_path: ""                # Client certificate path (optional)
    client_key_path: ""                 # Client private key path (optional)
    client_key_password: ""             # Client key password (optional)

  # =========================================================================
  # Phase 1: Multi-Provider Fallback Configuration
  # =========================================================================
  enable_fallback: true
  fallback_providers: ["openai", "anthropic"]
  automatic_failover: true
  provider_health_check_interval: 300
  max_provider_failures: 3
  provider_cooldown_period: 600
  fallback_strategy: "round_robin"  # Options: round_robin, priority, random
  
  # Provider endpoints
  endpoints:
    groq: "https://api.groq.com/openai/v1/chat/completions"
    openai: "https://api.openai.com/v1/chat/completions"
    anthropic: "https://api.anthropic.com/v1/messages"
    claude: "https://api.anthropic.com/v1/messages"

  # =========================================================================
  # Phase 2: Enterprise Monitoring & Metrics Configuration
  # =========================================================================
  monitoring:
    enable_detailed_metrics: true
    metrics_collection_interval: 30
    enable_performance_tracking: true
    enable_error_tracking: true
    enable_latency_tracking: true
    enable_cost_tracking: true
    prometheus_endpoint: "/metrics"
    health_check_endpoint: "/health"
    
    # Enhanced metrics collection
    metrics_collection:
      enabled: true
      batch_size: "${METRICS_BATCH_SIZE:100}"
      flush_interval_seconds: "${METRICS_FLUSH_INTERVAL:60}"
      retention_days: "${METRICS_RETENTION_DAYS:30}"
      include_request_headers: false
      include_response_metadata: true
    
    # Performance tracking enhancements
    performance_tracking:
      enabled: true
      response_time_percentiles: [50, 90, 95, 99]
      error_rate_threshold: "${ERROR_RATE_THRESHOLD:0.05}"
      latency_threshold_ms: "${LATENCY_THRESHOLD_MS:5000}"
      track_token_usage: true
      track_model_performance: true
    
    # Alert thresholds
    alert_thresholds:
      error_rate_percent: "${ALERT_ERROR_RATE:5.0}"
      latency_p95_seconds: "${ALERT_LATENCY_P95:10.0}"
      latency_p99_seconds: "${ALERT_LATENCY_P99:20.0}"
      success_rate_percent: "${ALERT_SUCCESS_RATE:95.0}"
      cost_per_hour_usd: "${ALERT_COST_LIMIT:100.0}"
      queue_size: "${ALERT_QUEUE_SIZE:1000}"
      provider_failure_consecutive: "${ALERT_PROVIDER_FAILURES:3}"
      
    # Enhanced alerting configuration
    alerts:
      enable_email: "${ENABLE_EMAIL_ALERTS:false}"
      enable_webhook: "${ENABLE_WEBHOOK_ALERTS:false}"
      enable_slack: "${ENABLE_SLACK_ALERTS:false}"
      enable_log_alerts: "${ENABLE_LOG_ALERTS:true}"
      webhook_url: "${WEBHOOK_URL:}"
      email_recipients: "${EMAIL_RECIPIENTS:[]}"
      slack_channel: "${SLACK_CHANNEL:}"
      log_level: "${ALERT_LOG_LEVEL:error}"
      
    # Quality assessment
    quality_assessment:
      enabled: "${ENABLE_QUALITY_ASSESSMENT:true}"
      sample_rate: "${QUALITY_SAMPLE_RATE:0.1}"
      validation_prompt: "${QUALITY_VALIDATION_PROMPT:Rate the quality of this response on a scale of 1-10 with brief justification}"
      min_quality_score: "${MIN_QUALITY_SCORE:7.0}"
      quality_tracking_window_hours: "${QUALITY_WINDOW_HOURS:24}"
      
  # Circuit breaker configuration per provider
  circuit_breaker:
    enable_per_provider: true
    failure_threshold: 5
    recovery_timeout_seconds: 60
    half_open_max_calls: 3
    state_change_callback: true
    
  # =========================================================================
  # Phase 3: Intelligent Caching & Performance Configuration  
  # =========================================================================
  caching:
    enable_semantic_cache: true
    cache_type: "memory"  # Options: memory, redis, file
    cache_ttl_seconds: 3600
    max_cache_size: 10000
    cache_hit_ratio_target: 0.7
    enable_cache_compression: true
    cache_key_strategy: "semantic_hash"  # Options: semantic_hash, prompt_hash, full_hash
    
    # Semantic similarity for cache matching
    similarity_threshold: 0.85
    enable_embedding_cache: true
    embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
    
    # Cache eviction policy
    eviction_policy: "lru"  # Options: lru, lfu, ttl, random
    background_refresh: true
    refresh_threshold: 0.1  # Refresh when TTL < 10%
    
  # Performance optimization
  performance:
    enable_adaptive_batching: true
    enable_request_queuing: true
    enable_load_balancing: true
    enable_auto_scaling: true
    
    # Adaptive batching
    min_batch_size: 1
    max_batch_size: 50
    optimal_batch_size: 8
    batch_timeout_seconds: 5
    adaptive_sizing_window: 100
    
    # Request queuing
    max_queue_size: 1000
    queue_timeout_seconds: 30
    priority_levels: 3
    
    # Load balancing
    load_balance_strategy: "least_connections"  # Options: round_robin, least_connections, weighted
    health_check_interval: 60
    
    # Auto-scaling
    scale_up_threshold: 0.8
    scale_down_threshold: 0.3
    min_instances: 1
    max_instances: 10
    scale_factor: 2

  # Provider-specific settings with full configurability
  provider_settings:
    groq:
      max_tokens: 4096
      temperature: 0.1
      supports_json_mode: true
      batch_size_limit: 20
      rate_limit_requests_per_minute: 6000
      optimal_batch_size: 8
      max_prompt_length: 8000
      retry_wait_min: 2
      retry_wait_max: 8
      retry_multiplier: 1
      connector_limit: 100
      connector_limit_per_host: 20
      priority: 1  # Higher priority = preferred provider
      cost_per_1k_tokens: 0.0001
      reliability_score: 0.95
      
    openai:
      max_tokens: 4096
      temperature: 0.1
      supports_json_mode: true
      batch_size_limit: 100
      rate_limit_requests_per_minute: 3000
      optimal_batch_size: 10
      max_prompt_length: 8000
      retry_wait_min: 3
      retry_wait_max: 12
      retry_multiplier: 1
      connector_limit: 50
      connector_limit_per_host: 10
      priority: 2
      cost_per_1k_tokens: 0.03
      reliability_score: 0.99
      
    anthropic:
      max_tokens: 4096
      temperature: 0.1
      supports_json_mode: false
      batch_size_limit: 50
      rate_limit_requests_per_minute: 1000
      optimal_batch_size: 5
      max_prompt_length: 8000
      retry_wait_min: 4
      retry_wait_max: 16
      retry_multiplier: 1.5
      anthropic_version: "2023-06-01"
      connector_limit: 30
      connector_limit_per_host: 5
      priority: 3
      cost_per_1k_tokens: 0.025
      reliability_score: 0.97
      
    claude:
      max_tokens: 4096
      temperature: 0.1
      supports_json_mode: false
      batch_size_limit: 50
      rate_limit_requests_per_minute: 1000
      optimal_batch_size: 5
      max_prompt_length: 8000
      retry_wait_min: 4
      retry_wait_max: 16
      retry_multiplier: 1.5
      anthropic_version: "2023-06-01"
      connector_limit: 30
      connector_limit_per_host: 5
      priority: 4
      cost_per_1k_tokens: 0.025
      reliability_score: 0.97
  
  health_check:
    enabled: true
    prompt: "Respond with 'OK'"
    interval_seconds: 300
    timeout_seconds: 10

# =============================================================================
# Timeouts Configuration
# =============================================================================
timeouts:
  request: "${REQUEST_TIMEOUT:30}"
  subprocess: "${SUBPROCESS_TIMEOUT:60}"
  llm_query: "${LLM_QUERY_TIMEOUT:60}"
  session_max_age: "${SESSION_MAX_AGE:3600}"

# =============================================================================
# Phase 3: Intelligent Caching & Performance Optimization
# =============================================================================
caching:
  enabled: "${ENABLE_CACHING:true}"
  type: "${CACHE_TYPE:semantic}"
  
  # Semantic cache configuration
  semantic_cache:
    enabled: "${ENABLE_SEMANTIC_CACHE:true}"
    similarity_threshold: "${SEMANTIC_SIMILARITY_THRESHOLD:0.85}"
    max_entries: "${SEMANTIC_CACHE_MAX_ENTRIES:10000}"
    ttl_hours: "${SEMANTIC_CACHE_TTL_HOURS:24}"
    embedding_model: "${EMBEDDING_MODEL:sentence-transformers/all-MiniLM-L6-v2}"
    cleanup_interval_hours: "${SEMANTIC_CACHE_CLEANUP_HOURS:6}"
    vector_dimension: "${VECTOR_DIMENSION:384}"
  
  # Response cache configuration
  response_cache:
    enabled: "${ENABLE_RESPONSE_CACHE:true}"
    max_size_mb: "${RESPONSE_CACHE_SIZE_MB:500}"
    compression_enabled: "${ENABLE_CACHE_COMPRESSION:true}"
    eviction_policy: "${CACHE_EVICTION_POLICY:lru}"
    compression_algorithm: "${COMPRESSION_ALGORITHM:gzip}"
  
  # Performance optimization
  performance_optimization:
    # Request batching
    request_batching:
      enabled: "${ENABLE_REQUEST_BATCHING:true}"
      max_batch_size: "${MAX_BATCH_SIZE:10}"
      timeout_ms: "${BATCH_TIMEOUT_MS:2000}"
      batch_accumulation_delay_ms: "${BATCH_DELAY_MS:100}"
      
    # Connection pooling
    connection_pooling:
      enabled: "${ENABLE_CONNECTION_POOLING:true}"
      max_connections: "${MAX_CONNECTIONS:100}"
      max_connections_per_host: "${MAX_CONNECTIONS_PER_HOST:20}"
      idle_timeout_seconds: "${IDLE_TIMEOUT_SECONDS:30}"
      connection_lifetime_seconds: "${CONNECTION_LIFETIME_SECONDS:300}"
      
    # Adaptive timeout configuration
    adaptive_timeout:
      enabled: "${ENABLE_ADAPTIVE_TIMEOUT:true}"
      base_timeout_seconds: "${BASE_TIMEOUT_SECONDS:30}"
      max_timeout_seconds: "${MAX_TIMEOUT_SECONDS:120}"
      min_timeout_seconds: "${MIN_TIMEOUT_SECONDS:5}"
      adjustment_factor: "${TIMEOUT_ADJUSTMENT_FACTOR:1.2}"
      success_rate_window: "${TIMEOUT_SUCCESS_WINDOW:100}"
      
    # Load balancing
    load_balancing:
      enabled: "${ENABLE_LOAD_BALANCING:true}"
      strategy: "${LOAD_BALANCE_STRATEGY:round_robin}"  # round_robin, weighted, least_connections
      health_check_interval_seconds: "${LB_HEALTH_CHECK_INTERVAL:60}"
      unhealthy_threshold: "${LB_UNHEALTHY_THRESHOLD:3}"
      healthy_threshold: "${LB_HEALTHY_THRESHOLD:2}"

# =============================================================================
# MCP Configuration
# =============================================================================
mcp:
  client_type: "langchain"
  generate_tools: true
  include_schemas: true
  generate_prompts: true
  generate_examples: true
  
  # Safety level mappings
  safety_mapping:
    white: "safe"
    grey: "caution"
    black: "restricted"
    admin_only: "admin_required"
  
  tool_template: "json"
  
  # Enhanced tool generation
  tool_generation:
    include_advanced_schemas: true
    generate_error_responses: true
    include_rate_limits: true
    generate_sdk_examples: true

  # Schema generation settings 
  input_schema_generation:
    include_descriptions: true
    include_examples: true
    include_constraints: true
    infer_additional_fields: true 
  output_schema_generation:
    include_success_responses: true
    include_error_responses: true
    include_metadata_fields: true
    enhance_with_domain_knowledge: true

  # Headers generation  
  headers_generation:
    auto_detect_auth_headers: true
    include_content_type: true
    include_user_agent: false
    include_rate_limit_headers: true
    default_content_type: "application/json"

# =============================================================================
# Exporter Configuration
# =============================================================================
exporter:
  types:
    - file
    - api
    - memory
  api_port: 8000
  api_auth: true
  memory_store: "faiss"

# =============================================================================
# Security Configuration
# =============================================================================
security:
  encrypt_outputs: "${ENCRYPT_OUTPUTS:false}"
  api_key_header: "${API_KEY_HEADER:X-API-Key}"
  rate_limit_by_key: "${RATE_LIMIT_BY_KEY:true}"
  input_sanitization: "${INPUT_SANITIZATION:true}"
  output_encoding: "${OUTPUT_ENCODING:true}"
  max_file_size: "${MAX_FILE_SIZE:50MB}"
  
  # Enhanced enterprise security features
  encryption:
    enabled: "${ENABLE_ENCRYPTION:false}"
    algorithm: "${ENCRYPTION_ALGORITHM:AES-256-GCM}"
    key_rotation_days: "${KEY_ROTATION_DAYS:30}"
    at_rest_encryption: "${AT_REST_ENCRYPTION:false}"
    in_transit_encryption: "${IN_TRANSIT_ENCRYPTION:true}"
  
  # PII scrubbing configuration
  pii_scrubbing:
    enabled: "${ENABLE_PII_SCRUBBING:true}"
    scrub_patterns:
      - name: "email"
        pattern: "${EMAIL_SCRUB_PATTERN:[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}}"
        replacement: "${EMAIL_REPLACEMENT:[EMAIL_REDACTED]}"
      - name: "phone"
        pattern: "${PHONE_SCRUB_PATTERN:(\\+?1[-\\s]?)?\\(?[0-9]{3}\\)?[-\\s]?[0-9]{3}[-\\s]?[0-9]{4}}"
        replacement: "${PHONE_REPLACEMENT:[PHONE_REDACTED]}"
      - name: "ssn"
        pattern: "${SSN_SCRUB_PATTERN:\\b\\d{3}-\\d{2}-\\d{4}\\b}"
        replacement: "${SSN_REPLACEMENT:[SSN_REDACTED]}"
      - name: "credit_card"
        pattern: "${CC_SCRUB_PATTERN:\\b(?:\\d{4}[-\\s]?){3}\\d{4}\\b}"
        replacement: "${CC_REPLACEMENT:[CC_REDACTED]}"
    custom_patterns: "${CUSTOM_PII_PATTERNS:[]}"
    audit_scrubbing: "${AUDIT_PII_SCRUBBING:true}"
  
  # Rate limiting & DDoS protection
  rate_limiting:
    enabled: "${ENABLE_RATE_LIMITING:true}"
    requests_per_minute: "${RATE_LIMIT_RPM:1000}"
    requests_per_hour: "${RATE_LIMIT_RPH:10000}"
    requests_per_day: "${RATE_LIMIT_RPD:50000}"
    burst_allowance: "${RATE_LIMIT_BURST:50}"
    ip_whitelist: "${RATE_LIMIT_WHITELIST:[]}"
    ip_blacklist: "${RATE_LIMIT_BLACKLIST:[]}"
    adaptive_limits: "${ADAPTIVE_RATE_LIMITS:true}"
    
  # Input validation & sanitization
  input_validation:
    enabled: "${ENABLE_INPUT_VALIDATION:true}"
    max_prompt_length: "${MAX_PROMPT_LENGTH:50000}"
    max_file_size_mb: "${MAX_FILE_SIZE_MB:10}"
    sanitize_html: "${SANITIZE_HTML:true}"
    block_malicious_patterns: "${BLOCK_MALICIOUS_PATTERNS:true}"
    validate_json_schema: "${VALIDATE_JSON_SCHEMA:true}"
    content_type_validation: "${CONTENT_TYPE_VALIDATION:true}"
  
  allowed_file_types: "${ALLOWED_FILE_TYPES:[.json, .yaml, .yml, .py]}"
  auth_header_patterns:
    api_key:
      - "X-API-Key"
      - "X-Api-Key"
      - "x-api-key"
      - "API-Key"
      - "apikey"
    bearer:
      - "Authorization"
      - "authorization"
    custom:
      - "X-Custom-Auth"
      - "X-Service-Token"

# =============================================================================
# Error Handling Configuration
# =============================================================================
error_handling:
  max_retries: "${MAX_RETRIES:3}"
  backoff_strategy: "${BACKOFF_STRATEGY:exponential}"
  initial_backoff_seconds: "${INITIAL_BACKOFF_SECONDS:1}"
  max_backoff_seconds: "${MAX_BACKOFF_SECONDS:60}"
  backoff_multiplier: "${BACKOFF_MULTIPLIER:2.0}"
  jitter_enabled: "${ENABLE_JITTER:true}"
  
  circuit_breaker:
    enabled: "${ENABLE_CIRCUIT_BREAKER:true}"
    failure_threshold: "${CIRCUIT_BREAKER_FAILURE_THRESHOLD:5}"
    recovery_timeout: "${CIRCUIT_BREAKER_RECOVERY_TIMEOUT:60}"
    half_open_max_calls: "${CIRCUIT_BREAKER_HALF_OPEN_CALLS:3}"
    
  dead_letter_queue: 
    enabled: "${ENABLE_DEAD_LETTER_QUEUE:true}"
    max_size: "${DLQ_MAX_SIZE:1000}"
    retention_hours: "${DLQ_RETENTION_HOURS:72}"
    
  retry_on_status_codes: "${RETRY_STATUS_CODES:[429, 502, 503, 504]}"
  retry_on_exceptions: "${RETRY_EXCEPTIONS:[RequestException, ClientError, TimeoutError, ConnectionError, SSLError]}"
  
  # Error categorization & handling
  error_classification:
    transient_errors: "${TRANSIENT_ERRORS:[429, 502, 503, 504, ConnectionError, TimeoutError]}"
    permanent_errors: "${PERMANENT_ERRORS:[400, 401, 403, 404, 422]}"
    retry_transient: "${RETRY_TRANSIENT:true}"
    fail_fast_permanent: "${FAIL_FAST_PERMANENT:true}"

# =============================================================================
# Monitoring Configuration  
# =============================================================================
monitoring:
  metrics_enabled: "${METRICS_ENABLED:true}"
  health_check_port: "${HEALTH_CHECK_PORT:8080}"
  prometheus_endpoint: "${PROMETHEUS_ENDPOINT:/metrics}"
  log_sampling_rate: "${LOG_SAMPLING_RATE:0.1}"
  slow_query_threshold: "${SLOW_QUERY_THRESHOLD:5}"
  
  # Enhanced metrics tracking
  tracked_metrics: "${TRACKED_METRICS:[requests_total, requests_duration_seconds, llm_calls_total, llm_tokens_used, errors_total, cache_hits_total, quality_scores]}"
  
  custom_metrics:
    enabled: "${ENABLE_CUSTOM_METRICS:true}"
    business_metrics: "${BUSINESS_METRICS:[conversion_rate, user_satisfaction, feature_usage]}"
    performance_metrics: "${PERFORMANCE_METRICS:[throughput, latency_percentiles, resource_utilization]}"
    
  dashboard:
    enabled: "${ENABLE_DASHBOARD:true}"
    port: "${DASHBOARD_PORT:3000}"
    refresh_interval_seconds: "${DASHBOARD_REFRESH:30}"
    
  # Monitoring integrations
  integrations:
    datadog:
      enabled: "${ENABLE_DATADOG:false}"
      api_key: "${DATADOG_API_KEY:}"
      app_key: "${DATADOG_APP_KEY:}"
    newrelic:
      enabled: "${ENABLE_NEWRELIC:false}"
      license_key: "${NEWRELIC_LICENSE_KEY:}"
    grafana:
      enabled: "${ENABLE_GRAFANA:false}"
      endpoint: "${GRAFANA_ENDPOINT:}"

# =============================================================================
# Telemetry Configuration
# =============================================================================
telemetry:
  tracing_enabled: "${TRACING_ENABLED:false}"
  metrics_enabled: "${TELEMETRY_METRICS_ENABLED:false}"
  logging_enabled: "${TELEMETRY_LOGGING_ENABLED:true}"
  
  # OpenTelemetry configuration
  otel:
    endpoint: "${OTEL_ENDPOINT:http://jaeger:14268}"
    service_name: "${OTEL_SERVICE_NAME:spec-analyzer-mcp}"
    service_version: "${OTEL_SERVICE_VERSION:1.0.0}"
    environment: "${OTEL_ENVIRONMENT:development}"
    
  # Distributed tracing
  tracing:
    sample_rate: "${TRACE_SAMPLE_RATE:0.1}"
    max_spans_per_trace: "${MAX_SPANS_PER_TRACE:1000}"
    span_attributes: "${SPAN_ATTRIBUTES:[semantic_name, complexity, user_context, permission_level, confidence_score]}"
    
  # Custom instrumentation
  instrumentation:
    auto_instrument: "${AUTO_INSTRUMENT:true}"
    instrument_llm_calls: "${INSTRUMENT_LLM_CALLS:true}"
    instrument_database: "${INSTRUMENT_DATABASE:true}"
    instrument_cache: "${INSTRUMENT_CACHE:true}"
    instrument_file_io: "${INSTRUMENT_FILE_IO:false}"
    
  # Data export
  exporters:
    console:
      enabled: "${CONSOLE_EXPORTER:false}"
    jaeger:
      enabled: "${JAEGER_EXPORTER:false}"
      endpoint: "${JAEGER_ENDPOINT:http://localhost:14268/api/traces}"
    otlp:
      enabled: "${OTLP_EXPORTER:false}"
      endpoint: "${OTLP_ENDPOINT:http://localhost:4317}"
      headers: "${OTLP_HEADERS:{}}"
