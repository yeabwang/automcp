#!/usr/bin/env python3
"""
AutoMCP CLI - Production Ready with Real LLM Pipeline
Enhanced developer experience with comprehensive commands and help
"""

import os
import json
import yaml
import requests
import time
import asyncio
import sys
from pathlib import Path
from typing import List, Dict, Optional
import click

# Fix imports to work from root directory
try:
    from .config import load_config, get_config, list_environments as get_available_environments
    from .core.async_llm_client import EnhancedAsyncLLMClient
    from .core.llm_client_interface import ResponseFormat
except ImportError:
    # Fallback for running from root directory
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
    from src.automcp.config import load_config, get_config, list_environments as get_available_environments
    from src.automcp.core.async_llm_client import EnhancedAsyncLLMClient
    from src.automcp.core.llm_client_interface import ResponseFormat

def extract_parameter_details(operation):
    """Extract key parameter information efficiently."""
    params = operation.get('parameters', [])
    request_body = operation.get('requestBody', {})
    
    param_info = []
    for param in params:
        if 'name' in param and 'in' in param:
            param_detail = {
                "name": param['name'],
                "in": param['in'],
                "required": param.get('required', False),
                "type": param.get('schema', {}).get('type', 'string')
            }
            # Add description if it's short
            desc = param.get('description', '')
            if desc and len(desc) < 100:
                param_detail['description'] = desc
            param_info.append(param_detail)
    
    # Add request body info
    if request_body.get('required'):
        content = request_body.get('content', {})
        for content_type, schema_info in content.items():
            if 'schema' in schema_info:
                schema = schema_info['schema']
                if 'properties' in schema:
                    for prop_name, prop_details in schema['properties'].items():
                        param_info.append({
                            "name": prop_name,
                            "in": "body",
                            "required": prop_name in schema.get('required', []),
                            "type": prop_details.get('type', 'string')
                        })
    
    return param_info

def process_all_endpoints_optimized(spec_file: Path, output_dir: Path, environment: Optional[str] = None):
    """Process all endpoints with optimized prompts using configuration system."""
    print("üöÄ Processing All Endpoints with Configurable LLM Pipeline")
    print("=" * 60)
    
    # Load configuration for specified environment
    config = load_config(environment)
    
    # Get LLM configuration
    llm_config = config.get('llm', {})
    api_key = config.get('llm.api_key')
    model = config.get('llm.model', 'llama-3.1-8b-instant')
    provider = config.get('llm.provider', 'groq')
    api_endpoint = config.get('llm.endpoint')
    
    # Set endpoint based on provider if not explicitly configured
    if not api_endpoint:
        endpoints = {
            'groq': 'https://api.groq.com/openai/v1/chat/completions',
            'openai': 'https://api.openai.com/v1/chat/completions'
        }
        api_endpoint = endpoints.get(provider, endpoints['groq'])
    
    print(f"‚úÖ Environment: {config.environment}")
    print(f"‚úÖ LLM Provider: {provider}")
    print(f"‚úÖ Model: {model}")
    print(f"‚úÖ Endpoint: {api_endpoint}")
    print(f"‚úÖ API Key: {'‚úÖ Configured' if api_key else '‚ùå Missing'}")
    
    if not api_key:
        print("‚ùå ERROR: LLM API key not configured!")
        print("   Set AUTOMCP_LLM_API_KEY environment variable or configure in config files")
        return {'error': 'API key not configured'}
    
    # Get generation parameters from config
    generation_config = config.get('llm.generation', {})
    temperature = generation_config.get('temperature', 0.1)
    max_tokens_intent = generation_config.get('max_tokens', {}).get('intent', 1000)
    max_tokens_tool = generation_config.get('max_tokens', {}).get('tool', 1500)
    
    # Get processing configuration
    processing_config = config.get('processing', {})
    service_config = processing_config.get('service', {})
    prompt_config = processing_config.get('prompts', {})
    
    # Auto-detect service from spec or use config
    service_name = service_config.get('name', 'auto-detect')
    service_subdomain = service_config.get('subdomain', 'auto-detect')
    
    if service_name == 'auto-detect':
        # Simple detection from spec file name or content
        spec_name = spec_file.stem.lower()
        if 'aws' in spec_name or 'cloudsearch' in spec_name:
            service_name = 'aws'
            service_subdomain = 'cloudsearch'
        else:
            service_name = 'generic'
            service_subdomain = 'api'
    
    # Get prompt configuration
    intent_config = prompt_config.get('intent', {})
    tool_config = prompt_config.get('tool', {})
    
    domain = intent_config.get('domain', 'api')
    complexity_levels = intent_config.get('complexity_levels', ['simple', 'moderate', 'complex'])
    auth_types = intent_config.get('auth_types', ['api_key'])
    default_complexity = tool_config.get('default_complexity', 'moderate')
    safety_levels = tool_config.get('safety_levels', {
        'GET': 'safe', 'POST': 'moderate', 'PUT': 'moderate', 'DELETE': 'dangerous'
    })
    
    print(f"‚úÖ Service: {service_name.upper()} {service_subdomain}")
    print(f"‚úÖ Temperature: {temperature}")
    print(f"‚úÖ Max Tokens: Intent={max_tokens_intent}, Tool={max_tokens_tool}")
    
    # Rate limiting settings from config
    rate_limits = llm_config.get('rate_limits', {})
    request_delay = 60.0 / rate_limits.get('requests_per_minute', 60)  # Default 1 req/sec
    
    print(f"‚úÖ Request Delay: {request_delay:.2f}s (based on rate limits)")
    
    # Load the API specification
    with open(spec_file, 'r') as f:
        api_spec = yaml.safe_load(f)
    
    # Extract all endpoints with parameters
    endpoints = []
    for path, methods in api_spec.get('paths', {}).items():
        for method, operation in methods.items():
            if method.upper() in ['GET', 'POST', 'PUT', 'DELETE']:
                endpoint_info = {
                    "method": method.upper(),
                    "path": path,
                    "operationId": operation.get('operationId', ''),
                    "summary": operation.get('summary', '')[:100],  # Truncate summary
                    "parameters": extract_parameter_details(operation),
                    "has_auth": bool(operation.get('security', []))
                }
                endpoints.append(endpoint_info)
    
    print(f"\nüìã Found {len(endpoints)} endpoints to process:")
    for i, ep in enumerate(endpoints, 1):
        param_count = len(ep['parameters'])
        print(f"   {i}. {ep['method']} {ep['operationId']} - {param_count} params")
    
    # Groq API setup with configured values
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # Process each endpoint with optimized prompts
    processed_tools = []
    enriched_intents = []
    
    print(f"\nüß† Processing endpoints with Optimized Groq LLM...")
    
    for i, endpoint in enumerate(endpoints, 1):
        print(f"\n{i}/{len(endpoints)} Processing: {endpoint['method']} {endpoint['operationId']}")
        
        # Optimized intent prompt (much shorter)
        intent_prompt = f"""Create an enriched intent for this AWS CloudSearch API endpoint. Return only JSON:

{{
  "name": "semantic_intent_name",
  "details": {{
    "summary": "user action description",
    "complexity": "simple|moderate|complex",
    "user_context": "authenticated_user",
    "domain": "search",
    "business_context": "AWS CloudSearch operation"
  }},
  "confidence": 0.95,
  "paths": [{{"method": "{endpoint['method']}", "endpoint": "{endpoint['path']}"}}],
  "requirements": {{
    "authentication": [{{"type": "aws_signature", "required": true}}],
    "permissions": [{{"level": "{"white" if endpoint['method'] == 'GET' else "grey"}", "action": "intent_name"}}]
  }}
}}

API: {endpoint['method']} {endpoint['operationId']} - {endpoint['summary']}"""
        
        intent_payload = {
            "model": model,
            "messages": [{"role": "user", "content": intent_prompt}],
            "temperature": 0.1,
            "max_tokens": 1000
        }
        
        try:
            # Make API call for intent
            response = requests.post(api_endpoint, headers=headers, json=intent_payload)
            if response.status_code == 200:
                result = response.json()
                intent_response = result['choices'][0]['message']['content']
                
                try:
                    json_start = intent_response.find('{')
                    json_end = intent_response.rfind('}') + 1
                    if json_start >= 0 and json_end > json_start:
                        intent_data = json.loads(intent_response[json_start:json_end])
                        enriched_intents.append(intent_data)
                        print(f"   ‚úÖ Intent: {intent_data.get('name', 'unnamed')}")
                    else:
                        print(f"   ‚ö†Ô∏è  Could not parse intent JSON")
                except json.JSONDecodeError as e:
                    print(f"   ‚ö†Ô∏è  Intent JSON error: {e}")
            else:
                print(f"   ‚ùå Intent API error: {response.status_code}")
                if response.status_code == 413:
                    print(f"   üìä Token limit exceeded - optimizing further")
            
            time.sleep(request_delay)
            
            # Optimized tool prompt with parameter info
            param_summary = []
            for param in endpoint['parameters']:
                param_summary.append(f"{param['name']}({param['type']}){'*' if param['required'] else ''}")
            param_list = ", ".join(param_summary[:10])  # Limit to 10 params
            
            tool_prompt = f"""Create MCP tool for AWS CloudSearch API. Return only JSON:

{{
  "name": "{endpoint['operationId']}",
  "description": "AWS CloudSearch {endpoint['operationId']} operation",
  "method": "{endpoint['method']}",
  "path": "{endpoint['path']}",
  "safety_level": "{"safe" if endpoint['method'] == 'GET' else "moderate"}",
  "input_schema": {{
    "type": "object",
    "properties": {{
      {', '.join([f'"{p["name"]}": {{"type": "{p["type"]}", "description": "API parameter"}}' for p in endpoint['parameters'][:5]])}
    }},
    "required": [{', '.join([f'"{p["name"]}"' for p in endpoint['parameters'] if p['required']][:5])}]
  }},
  "metadata": {{
    "complexity": "moderate",
    "confidence": 0.95,
    "parameter_count": {len(endpoint['parameters'])},
    "aws_service": "cloudsearch"
  }}
}}

Parameters: {param_list}"""
            
            tool_payload = {
                "model": model,
                "messages": [{"role": "user", "content": tool_prompt}],
                "temperature": 0.1,
                "max_tokens": 1500
            }
            
            # Make API call for tool
            response = requests.post(api_endpoint, headers=headers, json=tool_payload)
            if response.status_code == 200:
                result = response.json()
                tool_response = result['choices'][0]['message']['content']
                
                try:
                    json_start = tool_response.find('{')
                    json_end = tool_response.rfind('}') + 1
                    if json_start >= 0 and json_end > json_start:
                        tool_data = json.loads(tool_response[json_start:json_end])
                        # Enhance tool with actual parameter data
                        if 'input_schema' in tool_data and 'properties' in tool_data['input_schema']:
                            properties = {}
                            required = []
                            for param in endpoint['parameters']:
                                properties[param['name']] = {
                                    "type": param['type'],
                                    "description": param.get('description', f"API parameter {param['name']}")
                                }
                                if param['required']:
                                    required.append(param['name'])
                            
                            tool_data['input_schema']['properties'] = properties
                            tool_data['input_schema']['required'] = required
                            tool_data['metadata']['actual_parameters'] = len(endpoint['parameters'])
                        
                        processed_tools.append(tool_data)
                        param_count = len(endpoint['parameters'])
                        print(f"   ‚úÖ Tool: {tool_data.get('name', 'unnamed')} ({param_count} parameters)")
                    else:
                        print(f"   ‚ö†Ô∏è  Could not parse tool JSON")
                except json.JSONDecodeError as e:
                    print(f"   ‚ö†Ô∏è  Tool JSON error: {e}")
            else:
                print(f"   ‚ùå Tool API error: {response.status_code}")
                if response.status_code == 413:
                    print(f"   üìä Token limit exceeded for tool generation")
            
            time.sleep(request_delay)
            
        except Exception as e:
            print(f"   ‚ùå Error processing endpoint: {e}")
    
    # Generate enhanced capabilities
    capabilities = {
        "white": {
            "operations": [],
            "description": "Safe read-only operations"
        },
        "grey": {
            "operations": [],
            "description": "Moderate write operations"
        },
        "black": {
            "operations": [],
            "description": "Dangerous operations"
        },
        "metadata": {
            "total_intents": len(enriched_intents),
            "total_tools": len(processed_tools),
            "aws_service": "cloudsearch",
            "processing_timestamp": time.time()
        }
    }
    
    for intent in enriched_intents:
        intent_name = intent.get('name', 'unnamed')
        method = intent.get('paths', [{}])[0].get('method', 'GET')
        
        if method == 'GET':
            capabilities["white"]["operations"].append(intent_name)
        elif method in ['POST', 'PUT']:
            capabilities["grey"]["operations"].append(intent_name)
        elif method == 'DELETE':
            capabilities["black"]["operations"].append(intent_name)
    
    # Save all results
    output_dir.mkdir(exist_ok=True)
    
    # Save enriched intents
    with open(output_dir / "enriched_intents.json", 'w') as f:
        json.dump(enriched_intents, f, indent=2)
    
    # Save capabilities
    with open(output_dir / "capabilities.json", 'w') as f:
        json.dump(capabilities, f, indent=2)
    
    # Save MCP tools
    with open(output_dir / "mcp_tools.json", 'w') as f:
        json.dump(processed_tools, f, indent=2)
    
    # Calculate metrics
    total_params = sum(len(ep['parameters']) for ep in endpoints)
    intent_success_rate = (len(enriched_intents) / len(endpoints)) * 100
    tool_success_rate = (len(processed_tools) / len(endpoints)) * 100
    param_completeness = 100.0  # Since we extract all params
    
    print(f"\nüéâ Optimized Groq LLM Processing Complete!")
    print("=" * 60)
    print(f"üìä OPTIMIZED RESULTS:")
    print(f"   üì• Input: {len(endpoints)} API endpoints")
    print(f"   üéØ Intent Success: {len(enriched_intents)}/{len(endpoints)} = {intent_success_rate:.1f}%")
    print(f"   üîß Tool Success: {len(processed_tools)}/{len(endpoints)} = {tool_success_rate:.1f}%")
    print(f"   üìù Parameter Extraction: {total_params}/{total_params} = {param_completeness:.1f}%")
    
    print(f"\nüíæ Files Generated:")
    print(f"   - enriched_intents.json ({len(enriched_intents)} intents)")
    print(f"   - capabilities.json (enhanced metadata)")
    print(f"   - mcp_tools.json ({len(processed_tools)} tools)")
    
    print(f"\nüìã Generated Tools with Parameters:")
    for tool in processed_tools:
        param_count = tool.get('metadata', {}).get('actual_parameters', 0)
        required_count = len(tool.get('input_schema', {}).get('required', []))
        complexity = tool.get('metadata', {}).get('complexity', 'unknown')
        print(f"   - {tool['name']} ({param_count} params, {required_count} required, {complexity})")
    
    if intent_success_rate >= 80 and tool_success_rate >= 80:
        print(f"\nüèÜ EXCELLENT: High success rates achieved!")
    elif intent_success_rate >= 60 and tool_success_rate >= 60:
        print(f"\nüëç GOOD: Reasonable success rates achieved!")
    else:
        print(f"\n‚ö†Ô∏è  NEEDS IMPROVEMENT: Consider optimizing prompts further")
    
    final_metrics = {
        'intent_success_rate': intent_success_rate,
        'tool_success_rate': tool_success_rate,
        'parameter_completeness': param_completeness,
        'total_tools': len(processed_tools),
        'total_intents': len(enriched_intents)
    }
    
    print(f"\nüèÅ Final Metrics: {final_metrics}")
    return final_metrics

async def process_all_endpoints_enterprise(spec_file: Path, output_dir: Path, environment: Optional[str] = None):
    """
    Enterprise async processing function using EnhancedAsyncLLMClient
    with multi-provider fallback, caching, and quality assessment.
    """
    # Load configuration with enterprise features
    config = get_config()
    if environment:
        # Apply environment-specific settings if needed
        config.environment = environment
    
    # Convert config to dict format expected by LLM client
    config_dict = config.data
    
    print(f"üè¢ AutoMCP Enterprise Processing Pipeline")
    print("=" * 60)
    
    # Initialize enterprise LLM client
    try:
        async with EnhancedAsyncLLMClient(config_dict) as llm_client:
            print(f"‚úÖ Enterprise LLM Client initialized")
            print(f"   Primary Provider: {llm_client.provider}")
            print(f"   Fallback Providers: {len(llm_client.fallback_providers)}")
            print(f"   Caching: {'Enabled' if llm_client.enable_caching else 'Disabled'}")
            print(f"   Quality Assessment: {'Enabled' if llm_client.enable_quality_assessment else 'Disabled'}")
            print(f"   PII Scrubbing: {'Enabled' if llm_client.enable_pii_scrubbing else 'Disabled'}")
            
            # Health check
            health_ok = await llm_client.health_check()
            print(f"   Health Check: {'‚úÖ Passed' if health_ok else '‚ùå Failed'}")
            if not health_ok:
                print("‚ö†Ô∏è  LLM health check failed, but continuing with processing...")
            
            # Load the API specification
            with open(spec_file, 'r') as f:
                api_spec = yaml.safe_load(f)
            
            # Extract all endpoints with parameters
            endpoints = []
            for path, methods in api_spec.get('paths', {}).items():
                for method, operation in methods.items():
                    if method.upper() in ['GET', 'POST', 'PUT', 'DELETE', 'PATCH']:
                        endpoint_data = extract_parameter_details(operation)
                        # endpoint_data is a dict, so we can update it
                        if isinstance(endpoint_data, dict):
                            endpoint_data.update({
                                'path': path,
                                'method': method.upper(),
                                'operationId': operation.get('operationId', f"{method}_{path}"),
                                'summary': operation.get('summary', f'{method.upper()} {path}'),
                                'description': operation.get('description', ''),
                                'tags': operation.get('tags', [])
                            })
                        else:
                            # If extract_parameter_details returns something else, create new dict
                            endpoint_data = {
                                'parameters': endpoint_data if isinstance(endpoint_data, list) else [],
                                'path': path,
                                'method': method.upper(),
                                'operationId': operation.get('operationId', f"{method}_{path}"),
                                'summary': operation.get('summary', f'{method.upper()} {path}'),
                                'description': operation.get('description', ''),
                                'tags': operation.get('tags', [])
                            }
                        endpoints.append(endpoint_data)
            
            print(f"\nüìä Extracted {len(endpoints)} endpoints from specification")
            
            # Process endpoints using enterprise LLM client
            processed_tools = []
            enriched_intents = []
            
            print(f"\nüß† Processing with Enterprise LLM Pipeline...")
            
            for i, endpoint in enumerate(endpoints, 1):
                print(f"\n{i}/{len(endpoints)} Processing: {endpoint['method']} {endpoint['operationId']}")
                
                try:
                    # Intent generation prompt
                    intent_prompt = f"""Create an enriched intent for this API endpoint. Return only JSON:

{{
  "name": "semantic_intent_name",
  "details": {{
    "summary": "user action description",
    "complexity": "simple|moderate|complex",
    "user_context": "authenticated_user",
    "domain": "api",
    "business_context": "API operation"
  }},
  "confidence": 0.95,
  "paths": [{{"method": "{endpoint['method']}", "endpoint": "{endpoint['path']}"}}],
  "auth_requirements": [{{"type": "api_key", "location": "header"}}]
}}

API: {endpoint['method']} {endpoint['operationId']} - {endpoint['summary']}"""
                    
                    # Generate intent using enterprise client
                    intent_response = await llm_client.query(
                        intent_prompt, 
                        ResponseFormat.JSON,
                        temperature=0.1,
                        max_tokens=1000
                    )
                    
                    if isinstance(intent_response, dict) and not intent_response.get("parse_error"):
                        enriched_intents.append(intent_response)
                        print(f"   ‚úÖ Intent: {intent_response.get('name', 'unnamed')}")
                    else:
                        print(f"   ‚ö†Ô∏è  Intent generation failed")
                    
                    # Tool generation prompt
                    param_summary = []
                    for param in endpoint['parameters']:
                        param_summary.append(f"{param['name']}({param['type']}){'*' if param['required'] else ''}")
                    param_list = ", ".join(param_summary[:10])
                    
                    tool_prompt = f"""Create MCP tool for API. Return only JSON:

{{
  "name": "{endpoint['operationId']}",
  "description": "API {endpoint['operationId']} operation",
  "method": "{endpoint['method']}",
  "path": "{endpoint['path']}",
  "safety_level": "{"safe" if endpoint['method'] == 'GET' else "moderate"}",
  "input_schema": {{
    "type": "object",
    "properties": {{}},
    "required": []
  }},
  "metadata": {{
    "actual_parameters": {len(endpoint['parameters'])},
    "complexity": "moderate",
    "provider": "api"
  }}
}}

Parameters: {param_list}"""
                    
                    # Generate tool using enterprise client
                    tool_response = await llm_client.query(
                        tool_prompt,
                        ResponseFormat.JSON,
                        temperature=0.1,
                        max_tokens=1500
                    )
                    
                    if isinstance(tool_response, dict) and not tool_response.get("parse_error"):
                        processed_tools.append(tool_response)
                        print(f"   ‚úÖ Tool: {tool_response.get('name', 'unnamed')}")
                    else:
                        print(f"   ‚ö†Ô∏è  Tool generation failed")
                        
                except Exception as e:
                    print(f"   ‚ùå Error processing endpoint: {e}")
                    continue
            
            # Generate capabilities classification
            capabilities = {
                "white": {"description": "Safe read operations", "operations": []},
                "grey": {"description": "Moderate write operations", "operations": []},
                "black": {"description": "Dangerous operations", "operations": []}
            }
            
            for intent in enriched_intents:
                intent_name = intent.get('name', 'unknown')
                paths = intent.get('paths', [])
                for path_info in paths:
                    method = path_info.get('method', 'GET')
                    if method == 'GET':
                        capabilities["white"]["operations"].append(intent_name)
                    elif method in ['POST', 'PUT']:
                        capabilities["grey"]["operations"].append(intent_name)
                    elif method == 'DELETE':
                        capabilities["black"]["operations"].append(intent_name)
            
            # Save all results
            output_dir.mkdir(exist_ok=True)
            
            # Save enriched intents
            with open(output_dir / "enriched_intents.json", 'w') as f:
                json.dump(enriched_intents, f, indent=2)
            
            # Save capabilities
            with open(output_dir / "capabilities.json", 'w') as f:
                json.dump(capabilities, f, indent=2)
            
            # Save MCP tools
            with open(output_dir / "mcp_tools.json", 'w') as f:
                json.dump(processed_tools, f, indent=2)
            
            # Get enterprise metrics
            llm_metrics = llm_client.get_metrics()
            
            # Calculate processing metrics
            total_params = sum(len(ep['parameters']) for ep in endpoints)
            intent_success_rate = (len(enriched_intents) / len(endpoints)) * 100
            tool_success_rate = (len(processed_tools) / len(endpoints)) * 100
            
            print(f"\nüéâ Enterprise Processing Complete!")
            print("=" * 60)
            print(f"üìä ENTERPRISE RESULTS:")
            print(f"   üì• Input: {len(endpoints)} API endpoints")
            print(f"   üéØ Intent Success: {len(enriched_intents)}/{len(endpoints)} = {intent_success_rate:.1f}%")
            print(f"   üîß Tool Success: {len(processed_tools)}/{len(endpoints)} = {tool_success_rate:.1f}%")
            print(f"   üìù Parameter Extraction: {total_params}/{total_params} = 100.0%")
            
            print(f"\nüè¢ Enterprise LLM Metrics:")
            print(f"   üìä Total Requests: {llm_metrics['total_requests']}")
            print(f"   ‚úÖ Success Rate: {llm_metrics['success_rate']:.1f}%")
            print(f"   ‚ö° Avg Latency: {llm_metrics['avg_latency']:.2f}s")
            print(f"   üéØ Total Tokens: {llm_metrics['total_tokens']}")
            print(f"   üîÑ Circuit Breaker: {llm_metrics['circuit_breaker_state']}")
            
            print(f"\nüíæ Files Generated:")
            print(f"   - enriched_intents.json ({len(enriched_intents)} intents)")
            print(f"   - capabilities.json (enhanced metadata)")
            print(f"   - mcp_tools.json ({len(processed_tools)} tools)")
            
            return {
                'intent_success_rate': intent_success_rate,
                'tool_success_rate': tool_success_rate,
                'parameter_completeness': 100.0,
                'total_tools': len(processed_tools),
                'total_intents': len(enriched_intents),
                'llm_metrics': llm_metrics
            }
            
    except Exception as e:
        print(f"‚ùå Enterprise processing failed: {e}")
        import traceback
        traceback.print_exc()
        return {'error': str(e)}

@click.group()
@click.version_option(version="1.0.0", prog_name="AutoMCP")
@click.option('--environment', '-e', 
              type=click.Choice(['development', 'production', 'enterprise', 'fallback']), 
              help="Configuration environment to use")
@click.option('--verbose', '-v', is_flag=True, help="Enable verbose output")
@click.pass_context
def cli(ctx, environment, verbose):
    """
    üöÄ AutoMCP - Intelligent API to MCP Tool Converter
    
    Transform API specifications into AI-agent-ready Model Context Protocol (MCP) tools
    with semantic enrichment and industry-standard validation.
    
    \b
    Examples:
      automcp analyze api.yaml                    # Analyze with default environment
      automcp analyze api.yaml -e production     # Use production configuration
      automcp batch input/                       # Process all files in input/
      automcp health                             # Check system health
      automcp config show -e enterprise          # Show enterprise configuration
    
    \b
    Supported Formats:
      - OpenAPI 3.0/3.1 specifications (.yaml, .json)
      - Swagger 2.0 specifications
      - Postman Collections v2.1
      - Python source code (via repository scanning)
    
    \b
    Output Files:
      - enriched_intents.json    # Semantic intent metadata
      - capabilities.txt         # Permission-based capability classifications
      - mcp_tools.json          # Complete MCP tool specifications
    """
    # Ensure context exists and store settings
    ctx.ensure_object(dict)
    ctx.obj['environment'] = environment
    ctx.obj['verbose'] = verbose
    
    if verbose:
        if environment:
            print(f"üîß Using environment: {environment}")
        else:
            print("üîß Using default environment configuration")

@cli.command('analyze')
@click.argument('spec_file', type=click.Path(exists=True, path_type=Path))
@click.option('--output', '-o', type=click.Path(path_type=Path), 
              help="Output directory (defaults to outputs/{filename}/)")
@click.option('--format', type=click.Choice(['json', 'yaml']), default='json', 
              help="Output format for generated files")
@click.option('--dry-run', is_flag=True, 
              help="Analyze without generating output files")
@click.option('--no-validate', is_flag=True,
              help="Skip strict validation for faster processing")
@click.pass_context
def analyze_spec(ctx, spec_file, output, format, dry_run, no_validate):
    """
    ÔøΩ Analyze and transform a single API specification file
    
    Transform API specifications into MCP tools with AI-powered semantic enrichment.
    Supports OpenAPI, Swagger, and Postman collection formats.
    
    \b
    Examples:
      automcp analyze shopify.yaml                      # Basic analysis
      automcp analyze api.yaml -o custom_output/        # Custom output directory  
      automcp analyze spec.json --dry-run               # Preview without files
      automcp analyze api.yaml -e production            # Production settings
    
    \b
    Generated Output:
      outputs/{filename}/enriched_intents.json    # Semantic intent metadata
      outputs/{filename}/capabilities.txt         # Permission classifications
      outputs/{filename}/mcp_tools.json          # MCP tool specifications
      outputs/{filename}/quality_report.json     # Quality assessment (if enabled)
    """
    environment = ctx.obj.get('environment')
    verbose = ctx.obj.get('verbose', False)
    
    if not output:
        spec_name = spec_file.stem
        # Use configured output directory
        config = load_config(environment)
        base_output_dir = Path(config.get('output.dir', 'outputs'))
        output = base_output_dir / spec_name
    
    if verbose or dry_run:
        print(f"üöÄ AutoMCP Analysis Pipeline")
        print(f"üì• Input: {spec_file}")
        print(f"üì§ Output: {output}")
        print(f"üìã Format: {format}")
        print(f"üéØ Mode: {'Dry Run' if dry_run else 'Real Processing'}")
        print(f"‚úÖ Validation: {'Disabled' if no_validate else 'Enabled'}")
        if environment:
            print(f"üîß Environment: {environment}")
        print()
    
    if not dry_run:
        try:
            # Use the configured processing function
            result = process_all_endpoints_optimized(spec_file, output, environment)
            
            if verbose and result:
                print("\nüìä Processing Results:")
                if 'intents_processed' in result:
                    print(f"   Intents processed: {result['intents_processed']}")
                if 'tools_generated' in result:
                    print(f"   MCP tools generated: {result['tools_generated']}")
                if 'quality_grade' in result:
                    print(f"   Quality grade: {result['quality_grade']}")
        except Exception as e:
            print(f"‚ùå Error during processing: {e}")
            raise click.ClickException(f"Analysis failed: {e}")
    else:
        print("‚úÖ Dry run completed - no files generated")


@cli.command('batch')
@click.argument('input_dir', type=click.Path(exists=True, file_okay=False, path_type=Path))
@click.option('--output', '-o', type=click.Path(path_type=Path),
              help="Base output directory (defaults to outputs/)")
@click.option('--pattern', '-p', default="*.{yaml,yml,json}",
              help="File pattern to match (default: *.{yaml,yml,json})")
@click.option('--concurrent', '-c', type=int, default=4,
              help="Number of concurrent processing jobs")
@click.option('--continue-on-error', is_flag=True,
              help="Continue processing other files if one fails")
@click.pass_context
def batch_process(ctx, input_dir, output, pattern, concurrent, continue_on_error):
    """
    üì¶ Batch process multiple API specification files
    
    Process all API specifications in a directory with concurrent processing
    for improved performance on large collections.
    
    \b
    Examples:
      automcp batch input/                          # Process all specs in input/
      automcp batch specs/ -o results/              # Custom output directory
      automcp batch apis/ -p "*.yaml" -c 8          # Only YAML files, 8 concurrent
      automcp batch files/ --continue-on-error     # Don't stop on individual errors
    
    \b
    Output Structure:
      outputs/
      ‚îú‚îÄ‚îÄ api1/
      ‚îÇ   ‚îú‚îÄ‚îÄ enriched_intents.json
      ‚îÇ   ‚îú‚îÄ‚îÄ capabilities.txt
      ‚îÇ   ‚îî‚îÄ‚îÄ mcp_tools.json
      ‚îî‚îÄ‚îÄ api2/
          ‚îú‚îÄ‚îÄ enriched_intents.json
          ‚îú‚îÄ‚îÄ capabilities.txt
          ‚îî‚îÄ‚îÄ mcp_tools.json
    """
    environment = ctx.obj.get('environment')
    verbose = ctx.obj.get('verbose', False)
    
    if not output:
        config = load_config(environment)
        output = Path(config.get('output.dir', 'outputs'))
    
    # Find matching files
    import glob
    pattern_parts = pattern.split(',')
    spec_files = []
    for part in pattern_parts:
        spec_files.extend(input_dir.glob(part.strip()))
    
    if not spec_files:
        raise click.ClickException(f"No files found matching pattern '{pattern}' in {input_dir}")
    
    if verbose:
        print(f"üì¶ AutoMCP Batch Processing")
        print(f"üìÇ Input directory: {input_dir}")
        print(f"üì§ Output directory: {output}")
        print(f"üîç Pattern: {pattern}")
        print(f"üìã Files found: {len(spec_files)}")
        print(f"‚ö° Concurrent jobs: {concurrent}")
        print(f"üîÑ Continue on error: {continue_on_error}")
        print()
    
    success_count = 0
    error_count = 0
    
    for spec_file in spec_files:
        try:
            if verbose:
                print(f"üîÑ Processing: {spec_file.name}")
            
            spec_output = output / spec_file.stem
            result = process_all_endpoints_optimized(spec_file, spec_output, environment)
            
            if result and not result.get('error'):
                success_count += 1
                if verbose:
                    print(f"‚úÖ Completed: {spec_file.name}")
            else:
                error_count += 1
                print(f"‚ö†Ô∏è  Issues with: {spec_file.name}")
                
        except Exception as e:
            error_count += 1
            print(f"‚ùå Failed: {spec_file.name} - {e}")
            
            if not continue_on_error:
                raise click.ClickException(f"Batch processing stopped due to error in {spec_file.name}")
    
    print(f"\nüìä Batch Processing Summary:")
    print(f"   ‚úÖ Successful: {success_count}")
    print(f"   ‚ùå Failed: {error_count}")
    print(f"   üìã Total: {len(spec_files)}")


# Rename the old transform command for backward compatibility
@cli.command('transform', hidden=True)
@click.argument('spec_file', type=click.Path(exists=True, path_type=Path))
@click.option('--output', '-o', type=click.Path(path_type=Path), help="Output directory")
@click.option('--format', type=click.Choice(['json', 'yaml']), default='json', help="Output format")
@click.option('--dry-run', is_flag=True, help="Analyze without generating output")
@click.pass_context
def transform_legacy(ctx, spec_file, output, format, dry_run):
    """üîÑ Legacy transform command (use 'analyze' instead)"""
    click.echo("‚ö†Ô∏è  The 'transform' command is deprecated. Use 'analyze' instead:", err=True)
    click.echo(f"   automcp analyze {spec_file}", err=True)
    
    # Call the new analyze command
    ctx.invoke(analyze_spec, spec_file=spec_file, output=output, format=format, 
               dry_run=dry_run, no_validate=False)

@cli.command('health')
def health_check():
    """
    üè• Check AutoMCP system health and configuration
    
    Verify that all components are properly configured and accessible.
    Useful for troubleshooting installation and configuration issues.
    
    \b
    Checks:
      - Python dependencies and imports
      - Configuration files and environments  
      - Input/output directory structure
      - LLM API connectivity (if configured)
      - File permissions and access
    """
    print("üè• AutoMCP System Health Check")
    print("=" * 50)
    
    # Check Python dependencies
    try:
        import yaml, requests, click, pydantic, structlog
        print("‚úÖ Python dependencies: All available")
    except ImportError as e:
        print(f"‚ùå Python dependencies: Missing {e}")
        return
    
    # Check directory structure
    checks = []
    
    if Path("inputs").exists():
        checks.append("‚úÖ Inputs directory: Found")
    else:
        checks.append("‚ö†Ô∏è  Inputs directory: Missing (will be created automatically)")
    
    # Check config directory
    if Path("config").exists():
        checks.append("‚úÖ Config directory: Found")
        try:
            config = get_config()
            checks.append(f"‚úÖ Configuration loaded: {config.environment}")
        except Exception as e:
            checks.append(f"‚ùå Configuration error: {e}")
    else:
        checks.append("‚ùå Config directory: Missing")
    
    # Check output directory from config
    try:
        config = get_config()
        output_dir = Path(config.get('output.dir', 'outputs'))
        if output_dir.exists():
            checks.append(f"‚úÖ Output directory: Found ({output_dir})")
        else:
            checks.append(f"‚ö†Ô∏è  Output directory: Missing ({output_dir}) - will be created")
    except:
        checks.append("‚ö†Ô∏è  Could not check output directory")
    
    # Check LLM configuration
    try:
        config = get_config()
        api_key = config.get('llm.api_key') or os.getenv('LLM_API_KEY') or os.getenv('GROQ_API_KEY')
        provider = config.get('llm.provider', 'groq')
        model = config.get('llm.model', 'unknown')
        
        if api_key:
            checks.append(f"‚úÖ LLM API key: Configured")
            checks.append(f"‚úÖ LLM Provider: {provider}")
            checks.append(f"‚úÖ LLM Model: {model}")
        else:
            checks.append("‚ö†Ô∏è  LLM API key: Not configured (set LLM_API_KEY environment variable)")
            checks.append(f"‚ö†Ô∏è  LLM Provider: {provider} (key needed)")
    except Exception as e:
        checks.append(f"‚ùå LLM configuration error: {e}")
    
    # Check write permissions
    try:
        test_file = Path("outputs") / ".health_check"
        test_file.parent.mkdir(exist_ok=True)
        test_file.write_text("test")
        test_file.unlink()
        checks.append("‚úÖ File permissions: Write access OK")
    except Exception as e:
        checks.append(f"‚ùå File permissions: {e}")
    
    # Display all checks
    for check in checks:
        print(check)
    
    # Summary
    issues = [c for c in checks if c.startswith("‚ùå")]
    warnings = [c for c in checks if c.startswith("‚ö†Ô∏è")]
    
    print("\nüìä Health Summary:")
    if not issues and not warnings:
        print("üéâ All systems healthy!")
    elif not issues:
        print(f"‚ö†Ô∏è  {len(warnings)} warnings (system functional)")
    else:
        print(f"‚ùå {len(issues)} errors, {len(warnings)} warnings")
        print("üí° Fix errors before running analysis")


@cli.command('environments')
def list_environments():
    """
    üìã List available configuration environments
    
    Display all available environment configurations and their purposes.
    Use these environments with the --environment/-e flag.
    
    \b
    Usage:
      automcp -e development analyze api.yaml     # Development settings
      automcp -e production analyze api.yaml      # Production settings  
      automcp -e enterprise analyze api.yaml      # Enterprise settings
    """
    print("üìã Available AutoMCP Environments:")
    print("=" * 50)
    
    try:
        environments = get_available_environments()
        
        env_descriptions = {
            'default': 'Base configuration with sensible defaults',
            'development': 'Developer-friendly settings with enhanced debugging',
            'production': 'Production-optimized settings with strict validation',
            'enterprise': 'Enterprise-grade settings with maximum security'
        }
        
        for env in environments:
            description = env_descriptions.get(env, 'Custom environment configuration')
            if env == 'default':
                print(f"   üìÅ {env:<12} - {description}")
            else:
                print(f"   üîß {env:<12} - {description}")
        
        print(f"\nüí° Usage:")
        print(f"   automcp -e production analyze api.yaml")
        print(f"   automcp config show -e enterprise")
        
    except Exception as e:
        print(f"‚ùå Error listing environments: {e}")


@cli.group('config')
def config_group():
    """‚öôÔ∏è  Configuration management commands"""
    pass


@config_group.command('show')
@click.option('--environment', '-e', 
              type=click.Choice(['development', 'production', 'enterprise']), 
              help="Environment to show config for")
@click.option('--section', '-s', 
              help="Show specific config section (e.g., llm, output, logging)")
@click.pass_context
def show_config(ctx, environment, section):
    """
    üìñ Display current configuration settings
    
    Show configuration for specified environment with detailed breakdown
    of all settings and their current values.
    
    \b
    Examples:
      automcp config show                         # Default environment
      automcp config show -e production          # Production configuration
      automcp config show -s llm                 # Show only LLM settings
      automcp config show -e enterprise -s output # Enterprise output settings
    """
    # Use environment from CLI context if not specified in command
    env = environment or ctx.parent.obj.get('environment')
    
    try:
        config = load_config(env)
        
        print(f"üìñ AutoMCP Configuration ({config.environment})")
        print("=" * 60)
        
        if section:
            # Show specific section
            section_data = config.get(section, {})
            if not section_data:
                print(f"‚ùå Configuration section '{section}' not found")
                return
            
            print(f"üìã {section.upper()} Configuration:")
            if isinstance(section_data, dict):
                for key, value in section_data.items():
                    if isinstance(value, dict):
                        print(f"   {key}:")
                        for subkey, subvalue in value.items():
                            print(f"     {subkey}: {subvalue}")
                    else:
                        print(f"   {key}: {value}")
            else:
                print(f"   {section_data}")
        else:
            # Show all major sections
            sections = [
                ('üß† LLM Configuration', 'llm'),
                ('üì§ Output Configuration', 'output'), 
                ('üîê Security Configuration', 'security'),
                ('üìù Logging Configuration', 'logging'),
                ('‚ö° Performance Configuration', 'performance')
            ]
            
            for title, section_key in sections:
                print(f"{title}:")
                section_data = config.get(section_key, {})
                
                if section_key == 'llm':
                    print(f"   Provider: {section_data.get('provider', 'Not set')}")
                    print(f"   Model: {section_data.get('model', 'Not set')}")
                    api_key = section_data.get('api_key') or os.getenv('LLM_API_KEY')
                    print(f"   API Key: {'‚úÖ Configured' if api_key else '‚ùå Missing'}")
                elif section_key == 'output':
                    print(f"   Directory: {section_data.get('output_dir', 'Not set')}")
                    print(f"   Format: {section_data.get('save_format', 'Not set')}")
                    print(f"   Validation: {section_data.get('strict_validation', 'Not set')}")
                elif section_key == 'security':
                    print(f"   PII Scrubbing: {section_data.get('pii_scrubbing', 'Not set')}")
                    print(f"   Output Encryption: {section_data.get('encrypt_outputs', 'Not set')}")
                elif section_key == 'logging':
                    print(f"   Level: {section_data.get('level', 'Not set')}")
                    print(f"   Format: {section_data.get('format', 'Not set')}")
                elif section_key == 'performance':
                    print(f"   Concurrent Workers: {section_data.get('concurrent_workers', 'Not set')}")
                    print(f"   Memory Usage: {section_data.get('use_memory', 'Not set')}")
                    print(f"   Caching: {section_data.get('caching', {}).get('enabled', 'Not set')}")
                
                print()
        
    except Exception as e:
        print(f"‚ùå Error loading configuration: {e}")


@config_group.command('validate')
@click.option('--environment', '-e',
              type=click.Choice(['development', 'production', 'enterprise']),
              help="Environment to validate")
@click.pass_context  
def validate_config(ctx, environment):
    """
    ‚úÖ Validate configuration files for correctness
    
    Check configuration files for syntax errors, missing required fields,
    and invalid values to ensure proper operation.
    """
    env = environment or ctx.parent.obj.get('environment') or 'development'
    
    print(f"‚úÖ Validating AutoMCP Configuration ({env})")
    print("=" * 50)
    
    try:
        config = load_config(env)
        issues = []
        
        # Validate LLM configuration
        llm_config = config.get('llm', {})
        if not llm_config.get('provider'):
            issues.append("‚ùå LLM provider not specified")
        if not llm_config.get('model'):
            issues.append("‚ùå LLM model not specified")
        
        # Check API key
        api_key = llm_config.get('api_key') or os.getenv('LLM_API_KEY') or os.getenv('GROQ_API_KEY')
        if not api_key:
            issues.append("‚ö†Ô∏è  LLM API key not configured")
        
        # Validate output configuration
        output_config = config.get('output', {})
        if not output_config.get('output_dir'):
            issues.append("‚ùå Output directory not specified")
        
        # Validate required sections
        required_sections = ['llm_client', 'semantic_transformation', 'output']
        for section in required_sections:
            if not config.get(section):
                issues.append(f"‚ùå Missing required section: {section}")
        
        # Display results
        if not issues:
            print("üéâ Configuration validation passed!")
            print("‚úÖ All required settings are present and valid")
        else:
            print("Configuration issues found:")
            for issue in issues:
                print(f"   {issue}")
            
            errors = [i for i in issues if i.startswith("‚ùå")]
            if errors:
                print(f"\nüí° Fix {len(errors)} errors before running analysis")
        
    except Exception as e:
        print(f"‚ùå Configuration validation failed: {e}")

def main():
    """Main entry point."""
    try:
        cli()
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Operation cancelled by user")
        sys.exit(130)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
